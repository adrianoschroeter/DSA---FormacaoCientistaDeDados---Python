{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto 3 - Sistema de Recomendação com Spark MLLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *********** REQUISITO *********** \n",
    "Utilize Java JDK 11 e Apache Spark 2.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *********** DEFINIR O PROBLEMA DE NEGÓCIO *********** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste  projeto,  veremos  como  aplicar  um  algoritmo  de  Sistema  de Recomendação e calcular o affinity score, a fim de descobrir se um produto deve ou não ser recomendado a um usuário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> O que é um Sistema de recomendação? </strong>\n",
    "<ul style=\"list-style-type:square\">\n",
    "  <li>Também chamado de filtros colaborativos.</li>\n",
    "  <li>Analisa dados passados para compreender comportamentos de pessoas/entidades.</li>\n",
    "  <li>A recomendação é feita por similaridade de comportamento.</li>\n",
    "  <li>Recomendação baseada em usuários ou items.</li>\n",
    "  <li>Algoritmos de Recomendação esperam receber os dados em um formato específico: [user_ID, item_ID, score].</li>\n",
    "  <li>Score, também chamado rating, indica a preferência de um usuário sobre um item. Podem ser valores booleanos, ratings ou mesmo volume de vendas.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar os pacotes\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *********** CARGA DE DADOS *********** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset para este projeto será um \"dummy data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a Spark Session - usada quando se trabalha com Dataframes no Spark\n",
    "spSession = SparkSession.builder.master(\"local\").appName(\"SparkMLLib\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados no formato ALS (user, item, rating)\n",
    "avaliacaoRDD = sc.textFile(\"data/user-item.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *********** ANALISE EXPLORATORIA *********** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar o tipo de objeto\n",
    "type(avaliacaoRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar o tamanho do dataset\n",
    "avaliacaoRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apresentar os dados\n",
    "avaliacaoRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *********** LIMPEZA, TRANSFORMAÇÃO, MANIPULAÇÃO DE DADOS *********** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo as strings\n",
    "avaliacaoRDD2 = avaliacaoRDD.map(lambda l: l.split(',')).map(lambda l:(int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um Dataframe\n",
    "df_avaliacao = spSession.createDataFrame(avaliacaoRDD2, [\"user\", \"item\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avaliacao.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *********** CRIAR O MODELO PREDITIVO *********** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALS = Alternating Least Squares --> Algoritmo para sistema de recomendação, que otimiza a loss function \n",
    "# e funciona muito bem em ambientes paralelizados\n",
    "als = ALS(rank = 20, maxIter = 7)\n",
    "modelo = als.fit(df_avaliacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o Affinity Score\n",
    "modelo.userFactors.orderBy(\"id\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dataset de teste com usuários e items para rating\n",
    "df_teste = spSession.createDataFrame([(1001, 9003),(1001,9004),(1001,9005)], [\"user\", \"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões  \n",
    "# Quanto maior o Affinity Score, maior a probabilidade do usuário aceitar uma recomendação\n",
    "previsoes = (modelo.transform(df_teste).collect())\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
